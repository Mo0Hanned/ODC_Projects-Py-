{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10699098,"sourceType":"datasetVersion","datasetId":6630210}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import lib","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport keras\nimport os\nfrom pathlib import Path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-02-09T00:00:05.535344Z","iopub.execute_input":"2025-02-09T00:00:05.535615Z","iopub.status.idle":"2025-02-09T00:00:17.320481Z","shell.execute_reply.started":"2025-02-09T00:00:05.535587Z","shell.execute_reply":"2025-02-09T00:00:17.319555Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 300  # Number of epochs to train for.\nlatent_dim = 256  # Latent dimensionality of the encoding space.\nnum_samples = 12000  # Number of samples to train on.\ndata_path = \"/kaggle/input/eng2du/deu.txt\"","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:12:33.671441Z","iopub.execute_input":"2025-02-09T00:12:33.672110Z","iopub.status.idle":"2025-02-09T00:12:33.676167Z","shell.execute_reply.started":"2025-02-09T00:12:33.672076Z","shell.execute_reply":"2025-02-09T00:12:33.675221Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Prepare the data\n","metadata":{}},{"cell_type":"code","source":"# Vectorize the data.\ninput_texts = []\ntarget_texts = []\ninput_characters = set()\ntarget_characters = set()\nwith open(data_path, \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().split(\"\\n\")\nfor line in lines[: min(num_samples, len(lines) - 1)]:\n    input_text, target_text, _ = line.split(\"\\t\")\n    # We use \"tab\" as the \"start sequence\" character\n    # for the targets, and \"\\n\" as \"end sequence\" character.\n    target_text = \"\\t\" + target_text + \"\\n\"\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    for char in input_text:\n        if char not in input_characters:\n            input_characters.add(char)\n    for char in target_text:\n        if char not in target_characters:\n            target_characters.add(char)\n\ninput_characters = sorted(list(input_characters))\ntarget_characters = sorted(list(target_characters))\nnum_encoder_tokens = len(input_characters)\nnum_decoder_tokens = len(target_characters)\nmax_encoder_seq_length = max([len(txt) for txt in input_texts])\nmax_decoder_seq_length = max([len(txt) for txt in target_texts])\n\nprint(\"Number of samples:\", len(input_texts))\nprint(\"Number of unique input tokens:\", num_encoder_tokens)\nprint(\"Number of unique output tokens:\", num_decoder_tokens)\nprint(\"Max sequence length for inputs:\", max_encoder_seq_length)\nprint(\"Max sequence length for outputs:\", max_decoder_seq_length)","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:00:39.394260Z","iopub.execute_input":"2025-02-09T00:00:39.394619Z","iopub.status.idle":"2025-02-09T00:00:40.234367Z","shell.execute_reply.started":"2025-02-09T00:00:39.394589Z","shell.execute_reply":"2025-02-09T00:00:40.233420Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of samples: 12000\nNumber of unique input tokens: 71\nNumber of unique output tokens: 85\nMax sequence length for inputs: 15\nMax sequence length for outputs: 51\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\ntarget_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n\nencoder_input_data = np.zeros(\n    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n    dtype=\"float32\",\n)\ndecoder_input_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\"float32\",\n)\ndecoder_target_data = np.zeros(\n    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n    dtype=\"float32\",\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:00:43.438307Z","iopub.execute_input":"2025-02-09T00:00:43.439151Z","iopub.status.idle":"2025-02-09T00:00:43.444528Z","shell.execute_reply.started":"2025-02-09T00:00:43.439114Z","shell.execute_reply":"2025-02-09T00:00:43.443578Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t, input_token_index[char]] = 1.0\n    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n    for t, char in enumerate(target_text):\n        # decoder_target_data is ahead of decoder_input_data by one timestep\n        decoder_input_data[i, t, target_token_index[char]] = 1.0\n        if t > 0:\n            # decoder_target_data will be ahead by one timestep\n            # and will not include the start character.\n            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:00:45.764240Z","iopub.execute_input":"2025-02-09T00:00:45.765109Z","iopub.status.idle":"2025-02-09T00:00:46.297786Z","shell.execute_reply.started":"2025-02-09T00:00:45.765057Z","shell.execute_reply":"2025-02-09T00:00:46.297035Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Build the model\n","metadata":{}},{"cell_type":"code","source":"# Define an input sequence and process it.\nencoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\nencoder = keras.layers.LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_inputs)\n\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]\n\n# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:12:37.510498Z","iopub.execute_input":"2025-02-09T00:12:37.510860Z","iopub.status.idle":"2025-02-09T00:12:37.590986Z","shell.execute_reply.started":"2025-02-09T00:12:37.510830Z","shell.execute_reply":"2025-02-09T00:12:37.590337Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Train and save the model\n","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n)\nmodel.fit(\n    [encoder_input_data, decoder_input_data],\n    decoder_target_data,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.2,\n)\n# Save model\nmodel.save(\"s2s_model.keras\")","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:12:38.469289Z","iopub.execute_input":"2025-02-09T00:12:38.469755Z","iopub.status.idle":"2025-02-09T00:20:49.229814Z","shell.execute_reply.started":"2025-02-09T00:12:38.469722Z","shell.execute_reply":"2025-02-09T00:20:49.228631Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6549 - loss: 1.7018 - val_accuracy: 0.6516 - val_loss: 1.3356\nEpoch 2/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6980 - loss: 1.1027 - val_accuracy: 0.6927 - val_loss: 1.0741\nEpoch 3/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7484 - loss: 0.9293 - val_accuracy: 0.7484 - val_loss: 0.8987\nEpoch 4/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7831 - loss: 0.7834 - val_accuracy: 0.7702 - val_loss: 0.8212\nEpoch 5/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7981 - loss: 0.7162 - val_accuracy: 0.7912 - val_loss: 0.7474\nEpoch 6/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8087 - loss: 0.6689 - val_accuracy: 0.7997 - val_loss: 0.7147\nEpoch 7/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8160 - loss: 0.6357 - val_accuracy: 0.8007 - val_loss: 0.6998\nEpoch 8/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8219 - loss: 0.6153 - val_accuracy: 0.8044 - val_loss: 0.6792\nEpoch 9/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8282 - loss: 0.5930 - val_accuracy: 0.8068 - val_loss: 0.6674\nEpoch 10/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8338 - loss: 0.5728 - val_accuracy: 0.8168 - val_loss: 0.6324\nEpoch 11/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8387 - loss: 0.5549 - val_accuracy: 0.8199 - val_loss: 0.6261\nEpoch 12/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8429 - loss: 0.5386 - val_accuracy: 0.8239 - val_loss: 0.6095\nEpoch 13/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8483 - loss: 0.5219 - val_accuracy: 0.8248 - val_loss: 0.6066\nEpoch 14/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8512 - loss: 0.5121 - val_accuracy: 0.8302 - val_loss: 0.5871\nEpoch 15/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8542 - loss: 0.4996 - val_accuracy: 0.8330 - val_loss: 0.5786\nEpoch 16/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8563 - loss: 0.4936 - val_accuracy: 0.8331 - val_loss: 0.5757\nEpoch 17/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8602 - loss: 0.4807 - val_accuracy: 0.8375 - val_loss: 0.5604\nEpoch 18/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8640 - loss: 0.4665 - val_accuracy: 0.8389 - val_loss: 0.5599\nEpoch 19/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8666 - loss: 0.4594 - val_accuracy: 0.8419 - val_loss: 0.5462\nEpoch 20/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8684 - loss: 0.4503 - val_accuracy: 0.8437 - val_loss: 0.5413\nEpoch 21/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8711 - loss: 0.4426 - val_accuracy: 0.8457 - val_loss: 0.5358\nEpoch 22/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8732 - loss: 0.4357 - val_accuracy: 0.8472 - val_loss: 0.5315\nEpoch 23/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8759 - loss: 0.4250 - val_accuracy: 0.8479 - val_loss: 0.5265\nEpoch 24/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8774 - loss: 0.4195 - val_accuracy: 0.8495 - val_loss: 0.5212\nEpoch 25/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8794 - loss: 0.4141 - val_accuracy: 0.8509 - val_loss: 0.5166\nEpoch 26/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8817 - loss: 0.4062 - val_accuracy: 0.8532 - val_loss: 0.5122\nEpoch 27/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8825 - loss: 0.4020 - val_accuracy: 0.8542 - val_loss: 0.5082\nEpoch 28/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8850 - loss: 0.3935 - val_accuracy: 0.8557 - val_loss: 0.5033\nEpoch 29/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8862 - loss: 0.3872 - val_accuracy: 0.8563 - val_loss: 0.4996\nEpoch 30/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8878 - loss: 0.3826 - val_accuracy: 0.8568 - val_loss: 0.5001\nEpoch 31/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8901 - loss: 0.3776 - val_accuracy: 0.8587 - val_loss: 0.4957\nEpoch 32/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8925 - loss: 0.3683 - val_accuracy: 0.8590 - val_loss: 0.4948\nEpoch 33/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8934 - loss: 0.3664 - val_accuracy: 0.8603 - val_loss: 0.4903\nEpoch 34/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8941 - loss: 0.3620 - val_accuracy: 0.8609 - val_loss: 0.4884\nEpoch 35/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8963 - loss: 0.3556 - val_accuracy: 0.8617 - val_loss: 0.4870\nEpoch 36/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8985 - loss: 0.3471 - val_accuracy: 0.8613 - val_loss: 0.4852\nEpoch 37/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8995 - loss: 0.3456 - val_accuracy: 0.8620 - val_loss: 0.4852\nEpoch 38/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9011 - loss: 0.3408 - val_accuracy: 0.8630 - val_loss: 0.4826\nEpoch 39/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9015 - loss: 0.3373 - val_accuracy: 0.8632 - val_loss: 0.4846\nEpoch 40/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9047 - loss: 0.3276 - val_accuracy: 0.8643 - val_loss: 0.4784\nEpoch 41/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9048 - loss: 0.3281 - val_accuracy: 0.8641 - val_loss: 0.4809\nEpoch 42/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9059 - loss: 0.3218 - val_accuracy: 0.8653 - val_loss: 0.4756\nEpoch 43/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9081 - loss: 0.3173 - val_accuracy: 0.8658 - val_loss: 0.4760\nEpoch 44/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9094 - loss: 0.3124 - val_accuracy: 0.8658 - val_loss: 0.4760\nEpoch 45/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9095 - loss: 0.3102 - val_accuracy: 0.8662 - val_loss: 0.4765\nEpoch 46/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9108 - loss: 0.3085 - val_accuracy: 0.8669 - val_loss: 0.4785\nEpoch 47/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9132 - loss: 0.2990 - val_accuracy: 0.8659 - val_loss: 0.4791\nEpoch 48/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9150 - loss: 0.2932 - val_accuracy: 0.8680 - val_loss: 0.4743\nEpoch 49/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9152 - loss: 0.2924 - val_accuracy: 0.8668 - val_loss: 0.4757\nEpoch 50/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.2877 - val_accuracy: 0.8679 - val_loss: 0.4734\nEpoch 51/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9175 - loss: 0.2831 - val_accuracy: 0.8686 - val_loss: 0.4762\nEpoch 52/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9190 - loss: 0.2801 - val_accuracy: 0.8683 - val_loss: 0.4773\nEpoch 53/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9189 - loss: 0.2795 - val_accuracy: 0.8687 - val_loss: 0.4757\nEpoch 54/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9213 - loss: 0.2709 - val_accuracy: 0.8690 - val_loss: 0.4767\nEpoch 55/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9224 - loss: 0.2675 - val_accuracy: 0.8686 - val_loss: 0.4773\nEpoch 56/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9225 - loss: 0.2671 - val_accuracy: 0.8689 - val_loss: 0.4796\nEpoch 57/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9238 - loss: 0.2613 - val_accuracy: 0.8681 - val_loss: 0.4812\nEpoch 58/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9248 - loss: 0.2588 - val_accuracy: 0.8693 - val_loss: 0.4819\nEpoch 59/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9259 - loss: 0.2542 - val_accuracy: 0.8699 - val_loss: 0.4819\nEpoch 60/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9274 - loss: 0.2497 - val_accuracy: 0.8696 - val_loss: 0.4825\nEpoch 61/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9276 - loss: 0.2482 - val_accuracy: 0.8700 - val_loss: 0.4836\nEpoch 62/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9294 - loss: 0.2437 - val_accuracy: 0.8692 - val_loss: 0.4882\nEpoch 63/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9307 - loss: 0.2397 - val_accuracy: 0.8700 - val_loss: 0.4882\nEpoch 64/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9316 - loss: 0.2372 - val_accuracy: 0.8694 - val_loss: 0.4902\nEpoch 65/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9323 - loss: 0.2353 - val_accuracy: 0.8703 - val_loss: 0.4895\nEpoch 66/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9343 - loss: 0.2285 - val_accuracy: 0.8695 - val_loss: 0.4903\nEpoch 67/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9342 - loss: 0.2277 - val_accuracy: 0.8698 - val_loss: 0.4929\nEpoch 68/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9351 - loss: 0.2228 - val_accuracy: 0.8703 - val_loss: 0.4914\nEpoch 69/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9350 - loss: 0.2238 - val_accuracy: 0.8701 - val_loss: 0.4970\nEpoch 70/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9363 - loss: 0.2190 - val_accuracy: 0.8707 - val_loss: 0.4939\nEpoch 71/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.2168 - val_accuracy: 0.8697 - val_loss: 0.4994\nEpoch 72/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.2111 - val_accuracy: 0.8702 - val_loss: 0.4999\nEpoch 73/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9396 - loss: 0.2099 - val_accuracy: 0.8707 - val_loss: 0.4996\nEpoch 74/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.2065 - val_accuracy: 0.8696 - val_loss: 0.5078\nEpoch 75/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9410 - loss: 0.2043 - val_accuracy: 0.8695 - val_loss: 0.5076\nEpoch 76/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9411 - loss: 0.2020 - val_accuracy: 0.8706 - val_loss: 0.5072\nEpoch 77/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9425 - loss: 0.1983 - val_accuracy: 0.8701 - val_loss: 0.5085\nEpoch 78/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9428 - loss: 0.1974 - val_accuracy: 0.8699 - val_loss: 0.5138\nEpoch 79/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9441 - loss: 0.1945 - val_accuracy: 0.8701 - val_loss: 0.5169\nEpoch 80/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9443 - loss: 0.1914 - val_accuracy: 0.8698 - val_loss: 0.5182\nEpoch 81/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9458 - loss: 0.1875 - val_accuracy: 0.8691 - val_loss: 0.5213\nEpoch 82/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9460 - loss: 0.1877 - val_accuracy: 0.8700 - val_loss: 0.5237\nEpoch 83/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9470 - loss: 0.1833 - val_accuracy: 0.8700 - val_loss: 0.5223\nEpoch 84/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.1820 - val_accuracy: 0.8700 - val_loss: 0.5247\nEpoch 85/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9485 - loss: 0.1793 - val_accuracy: 0.8699 - val_loss: 0.5288\nEpoch 86/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.1778 - val_accuracy: 0.8686 - val_loss: 0.5324\nEpoch 87/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.1753 - val_accuracy: 0.8693 - val_loss: 0.5371\nEpoch 88/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9501 - loss: 0.1724 - val_accuracy: 0.8692 - val_loss: 0.5375\nEpoch 89/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9502 - loss: 0.1721 - val_accuracy: 0.8683 - val_loss: 0.5480\nEpoch 90/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9517 - loss: 0.1669 - val_accuracy: 0.8697 - val_loss: 0.5417\nEpoch 91/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9527 - loss: 0.1643 - val_accuracy: 0.8705 - val_loss: 0.5400\nEpoch 92/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9523 - loss: 0.1642 - val_accuracy: 0.8689 - val_loss: 0.5480\nEpoch 93/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9537 - loss: 0.1611 - val_accuracy: 0.8663 - val_loss: 0.5605\nEpoch 94/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9538 - loss: 0.1604 - val_accuracy: 0.8690 - val_loss: 0.5523\nEpoch 95/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9548 - loss: 0.1571 - val_accuracy: 0.8696 - val_loss: 0.5512\nEpoch 96/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9551 - loss: 0.1551 - val_accuracy: 0.8685 - val_loss: 0.5558\nEpoch 97/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9553 - loss: 0.1541 - val_accuracy: 0.8683 - val_loss: 0.5631\nEpoch 98/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9565 - loss: 0.1516 - val_accuracy: 0.8693 - val_loss: 0.5610\nEpoch 99/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9574 - loss: 0.1490 - val_accuracy: 0.8687 - val_loss: 0.5611\nEpoch 100/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9571 - loss: 0.1478 - val_accuracy: 0.8688 - val_loss: 0.5661\nEpoch 101/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9579 - loss: 0.1456 - val_accuracy: 0.8682 - val_loss: 0.5718\nEpoch 102/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9584 - loss: 0.1441 - val_accuracy: 0.8687 - val_loss: 0.5696\nEpoch 103/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9589 - loss: 0.1420 - val_accuracy: 0.8688 - val_loss: 0.5708\nEpoch 104/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.1400 - val_accuracy: 0.8693 - val_loss: 0.5749\nEpoch 105/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9601 - loss: 0.1387 - val_accuracy: 0.8682 - val_loss: 0.5808\nEpoch 106/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9602 - loss: 0.1382 - val_accuracy: 0.8685 - val_loss: 0.5823\nEpoch 107/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9609 - loss: 0.1357 - val_accuracy: 0.8683 - val_loss: 0.5863\nEpoch 108/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9616 - loss: 0.1329 - val_accuracy: 0.8675 - val_loss: 0.5899\nEpoch 109/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9618 - loss: 0.1323 - val_accuracy: 0.8673 - val_loss: 0.5972\nEpoch 110/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9624 - loss: 0.1299 - val_accuracy: 0.8682 - val_loss: 0.5964\nEpoch 111/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9629 - loss: 0.1287 - val_accuracy: 0.8675 - val_loss: 0.5951\nEpoch 112/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9632 - loss: 0.1270 - val_accuracy: 0.8677 - val_loss: 0.6011\nEpoch 113/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9637 - loss: 0.1263 - val_accuracy: 0.8681 - val_loss: 0.6019\nEpoch 114/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9637 - loss: 0.1250 - val_accuracy: 0.8674 - val_loss: 0.6078\nEpoch 115/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9640 - loss: 0.1243 - val_accuracy: 0.8674 - val_loss: 0.6095\nEpoch 116/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9644 - loss: 0.1224 - val_accuracy: 0.8676 - val_loss: 0.6118\nEpoch 117/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9654 - loss: 0.1200 - val_accuracy: 0.8675 - val_loss: 0.6146\nEpoch 118/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9659 - loss: 0.1175 - val_accuracy: 0.8660 - val_loss: 0.6226\nEpoch 119/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9660 - loss: 0.1173 - val_accuracy: 0.8660 - val_loss: 0.6198\nEpoch 120/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.1156 - val_accuracy: 0.8665 - val_loss: 0.6280\nEpoch 121/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9669 - loss: 0.1147 - val_accuracy: 0.8657 - val_loss: 0.6358\nEpoch 122/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9674 - loss: 0.1128 - val_accuracy: 0.8662 - val_loss: 0.6302\nEpoch 123/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9678 - loss: 0.1110 - val_accuracy: 0.8653 - val_loss: 0.6370\nEpoch 124/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9679 - loss: 0.1108 - val_accuracy: 0.8662 - val_loss: 0.6381\nEpoch 125/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9681 - loss: 0.1102 - val_accuracy: 0.8665 - val_loss: 0.6368\nEpoch 126/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9684 - loss: 0.1082 - val_accuracy: 0.8655 - val_loss: 0.6434\nEpoch 127/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.1060 - val_accuracy: 0.8668 - val_loss: 0.6401\nEpoch 128/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9691 - loss: 0.1061 - val_accuracy: 0.8658 - val_loss: 0.6470\nEpoch 129/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9694 - loss: 0.1048 - val_accuracy: 0.8653 - val_loss: 0.6490\nEpoch 130/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9699 - loss: 0.1031 - val_accuracy: 0.8662 - val_loss: 0.6506\nEpoch 131/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.1015 - val_accuracy: 0.8656 - val_loss: 0.6540\nEpoch 132/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9706 - loss: 0.1007 - val_accuracy: 0.8656 - val_loss: 0.6588\nEpoch 133/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9712 - loss: 0.0997 - val_accuracy: 0.8649 - val_loss: 0.6634\nEpoch 134/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.0993 - val_accuracy: 0.8651 - val_loss: 0.6692\nEpoch 135/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9718 - loss: 0.0975 - val_accuracy: 0.8655 - val_loss: 0.6684\nEpoch 136/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9717 - loss: 0.0969 - val_accuracy: 0.8656 - val_loss: 0.6705\nEpoch 137/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9727 - loss: 0.0938 - val_accuracy: 0.8651 - val_loss: 0.6774\nEpoch 138/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0929 - val_accuracy: 0.8646 - val_loss: 0.6811\nEpoch 139/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9727 - loss: 0.0928 - val_accuracy: 0.8651 - val_loss: 0.6770\nEpoch 140/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.0922 - val_accuracy: 0.8640 - val_loss: 0.6846\nEpoch 141/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.0912 - val_accuracy: 0.8642 - val_loss: 0.6844\nEpoch 142/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9734 - loss: 0.0910 - val_accuracy: 0.8643 - val_loss: 0.6922\nEpoch 143/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9737 - loss: 0.0898 - val_accuracy: 0.8638 - val_loss: 0.6960\nEpoch 144/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0877 - val_accuracy: 0.8638 - val_loss: 0.6919\nEpoch 145/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9740 - loss: 0.0883 - val_accuracy: 0.8641 - val_loss: 0.7004\nEpoch 146/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9749 - loss: 0.0868 - val_accuracy: 0.8638 - val_loss: 0.7049\nEpoch 147/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9751 - loss: 0.0853 - val_accuracy: 0.8644 - val_loss: 0.7057\nEpoch 148/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9755 - loss: 0.0837 - val_accuracy: 0.8649 - val_loss: 0.7058\nEpoch 149/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.0834 - val_accuracy: 0.8645 - val_loss: 0.7111\nEpoch 150/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0823 - val_accuracy: 0.8636 - val_loss: 0.7095\nEpoch 151/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.0821 - val_accuracy: 0.8644 - val_loss: 0.7164\nEpoch 152/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9762 - loss: 0.0813 - val_accuracy: 0.8638 - val_loss: 0.7212\nEpoch 153/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9767 - loss: 0.0801 - val_accuracy: 0.8643 - val_loss: 0.7130\nEpoch 154/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.0798 - val_accuracy: 0.8640 - val_loss: 0.7234\nEpoch 155/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9763 - loss: 0.0789 - val_accuracy: 0.8643 - val_loss: 0.7212\nEpoch 156/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0772 - val_accuracy: 0.8629 - val_loss: 0.7295\nEpoch 157/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0775 - val_accuracy: 0.8642 - val_loss: 0.7306\nEpoch 158/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9775 - loss: 0.0760 - val_accuracy: 0.8634 - val_loss: 0.7337\nEpoch 159/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0756 - val_accuracy: 0.8633 - val_loss: 0.7331\nEpoch 160/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0747 - val_accuracy: 0.8628 - val_loss: 0.7408\nEpoch 161/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0739 - val_accuracy: 0.8639 - val_loss: 0.7384\nEpoch 162/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9782 - loss: 0.0738 - val_accuracy: 0.8640 - val_loss: 0.7444\nEpoch 163/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0726 - val_accuracy: 0.8640 - val_loss: 0.7444\nEpoch 164/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0710 - val_accuracy: 0.8636 - val_loss: 0.7462\nEpoch 165/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0700 - val_accuracy: 0.8633 - val_loss: 0.7528\nEpoch 166/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0694 - val_accuracy: 0.8632 - val_loss: 0.7569\nEpoch 167/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9793 - loss: 0.0691 - val_accuracy: 0.8636 - val_loss: 0.7609\nEpoch 168/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9797 - loss: 0.0687 - val_accuracy: 0.8625 - val_loss: 0.7616\nEpoch 169/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.0678 - val_accuracy: 0.8630 - val_loss: 0.7609\nEpoch 170/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0673 - val_accuracy: 0.8624 - val_loss: 0.7676\nEpoch 171/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0668 - val_accuracy: 0.8628 - val_loss: 0.7656\nEpoch 172/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9805 - loss: 0.0654 - val_accuracy: 0.8625 - val_loss: 0.7687\nEpoch 173/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0647 - val_accuracy: 0.8625 - val_loss: 0.7776\nEpoch 174/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0643 - val_accuracy: 0.8632 - val_loss: 0.7778\nEpoch 175/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9809 - loss: 0.0640 - val_accuracy: 0.8635 - val_loss: 0.7770\nEpoch 176/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0627 - val_accuracy: 0.8621 - val_loss: 0.7808\nEpoch 177/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9810 - loss: 0.0634 - val_accuracy: 0.8640 - val_loss: 0.7766\nEpoch 178/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0622 - val_accuracy: 0.8629 - val_loss: 0.7793\nEpoch 179/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0610 - val_accuracy: 0.8627 - val_loss: 0.7921\nEpoch 180/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0603 - val_accuracy: 0.8620 - val_loss: 0.7922\nEpoch 181/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.0601 - val_accuracy: 0.8631 - val_loss: 0.7878\nEpoch 182/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0599 - val_accuracy: 0.8623 - val_loss: 0.7963\nEpoch 183/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0594 - val_accuracy: 0.8618 - val_loss: 0.7991\nEpoch 184/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0584 - val_accuracy: 0.8621 - val_loss: 0.7974\nEpoch 185/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0579 - val_accuracy: 0.8614 - val_loss: 0.8017\nEpoch 186/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.0576 - val_accuracy: 0.8618 - val_loss: 0.8012\nEpoch 187/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0571 - val_accuracy: 0.8627 - val_loss: 0.8047\nEpoch 188/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0561 - val_accuracy: 0.8618 - val_loss: 0.8078\nEpoch 189/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.0565 - val_accuracy: 0.8619 - val_loss: 0.8123\nEpoch 190/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9830 - loss: 0.0553 - val_accuracy: 0.8624 - val_loss: 0.8117\nEpoch 191/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.0545 - val_accuracy: 0.8606 - val_loss: 0.8204\nEpoch 192/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9836 - loss: 0.0547 - val_accuracy: 0.8613 - val_loss: 0.8154\nEpoch 193/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0547 - val_accuracy: 0.8616 - val_loss: 0.8183\nEpoch 194/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0548 - val_accuracy: 0.8621 - val_loss: 0.8216\nEpoch 195/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0540 - val_accuracy: 0.8621 - val_loss: 0.8252\nEpoch 196/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0536 - val_accuracy: 0.8619 - val_loss: 0.8307\nEpoch 197/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0511 - val_accuracy: 0.8613 - val_loss: 0.8308\nEpoch 198/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0513 - val_accuracy: 0.8611 - val_loss: 0.8273\nEpoch 199/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0514 - val_accuracy: 0.8616 - val_loss: 0.8316\nEpoch 200/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0525 - val_accuracy: 0.8613 - val_loss: 0.8360\nEpoch 201/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9849 - loss: 0.0503 - val_accuracy: 0.8604 - val_loss: 0.8393\nEpoch 202/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0509 - val_accuracy: 0.8611 - val_loss: 0.8397\nEpoch 203/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0489 - val_accuracy: 0.8617 - val_loss: 0.8375\nEpoch 204/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0488 - val_accuracy: 0.8614 - val_loss: 0.8473\nEpoch 205/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0506 - val_accuracy: 0.8616 - val_loss: 0.8418\nEpoch 206/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0482 - val_accuracy: 0.8621 - val_loss: 0.8477\nEpoch 207/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0480 - val_accuracy: 0.8611 - val_loss: 0.8505\nEpoch 208/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0474 - val_accuracy: 0.8618 - val_loss: 0.8536\nEpoch 209/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0465 - val_accuracy: 0.8611 - val_loss: 0.8528\nEpoch 210/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0467 - val_accuracy: 0.8618 - val_loss: 0.8539\nEpoch 211/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0463 - val_accuracy: 0.8609 - val_loss: 0.8541\nEpoch 212/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0465 - val_accuracy: 0.8610 - val_loss: 0.8635\nEpoch 213/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0456 - val_accuracy: 0.8612 - val_loss: 0.8666\nEpoch 214/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0461 - val_accuracy: 0.8611 - val_loss: 0.8621\nEpoch 215/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0452 - val_accuracy: 0.8609 - val_loss: 0.8687\nEpoch 216/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 0.0443 - val_accuracy: 0.8599 - val_loss: 0.8705\nEpoch 217/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0443 - val_accuracy: 0.8600 - val_loss: 0.8735\nEpoch 218/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0446 - val_accuracy: 0.8608 - val_loss: 0.8756\nEpoch 219/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0441 - val_accuracy: 0.8606 - val_loss: 0.8778\nEpoch 220/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0434 - val_accuracy: 0.8611 - val_loss: 0.8780\nEpoch 221/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0433 - val_accuracy: 0.8604 - val_loss: 0.8815\nEpoch 222/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0430 - val_accuracy: 0.8609 - val_loss: 0.8791\nEpoch 223/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9870 - loss: 0.0423 - val_accuracy: 0.8606 - val_loss: 0.8816\nEpoch 224/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0421 - val_accuracy: 0.8604 - val_loss: 0.8869\nEpoch 225/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0418 - val_accuracy: 0.8599 - val_loss: 0.8854\nEpoch 226/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0410 - val_accuracy: 0.8607 - val_loss: 0.8888\nEpoch 227/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0403 - val_accuracy: 0.8603 - val_loss: 0.8926\nEpoch 228/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0401 - val_accuracy: 0.8607 - val_loss: 0.8939\nEpoch 229/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0405 - val_accuracy: 0.8607 - val_loss: 0.8935\nEpoch 230/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0405 - val_accuracy: 0.8600 - val_loss: 0.8952\nEpoch 231/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.0397 - val_accuracy: 0.8606 - val_loss: 0.8935\nEpoch 232/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0389 - val_accuracy: 0.8603 - val_loss: 0.8996\nEpoch 233/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0394 - val_accuracy: 0.8600 - val_loss: 0.9036\nEpoch 234/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.0396 - val_accuracy: 0.8597 - val_loss: 0.9017\nEpoch 235/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.0380 - val_accuracy: 0.8602 - val_loss: 0.9043\nEpoch 236/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0390 - val_accuracy: 0.8603 - val_loss: 0.9055\nEpoch 237/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.0382 - val_accuracy: 0.8601 - val_loss: 0.9020\nEpoch 238/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0378 - val_accuracy: 0.8600 - val_loss: 0.9036\nEpoch 239/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0378 - val_accuracy: 0.8603 - val_loss: 0.9127\nEpoch 240/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0375 - val_accuracy: 0.8600 - val_loss: 0.9188\nEpoch 241/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0375 - val_accuracy: 0.8603 - val_loss: 0.9167\nEpoch 242/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0373 - val_accuracy: 0.8602 - val_loss: 0.9164\nEpoch 243/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0367 - val_accuracy: 0.8590 - val_loss: 0.9185\nEpoch 244/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0361 - val_accuracy: 0.8595 - val_loss: 0.9174\nEpoch 245/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0367 - val_accuracy: 0.8604 - val_loss: 0.9208\nEpoch 246/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0355 - val_accuracy: 0.8589 - val_loss: 0.9261\nEpoch 247/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0358 - val_accuracy: 0.8602 - val_loss: 0.9255\nEpoch 248/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0357 - val_accuracy: 0.8603 - val_loss: 0.9249\nEpoch 249/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.0353 - val_accuracy: 0.8596 - val_loss: 0.9249\nEpoch 250/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0355 - val_accuracy: 0.8595 - val_loss: 0.9327\nEpoch 251/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0357 - val_accuracy: 0.8591 - val_loss: 0.9300\nEpoch 252/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9885 - loss: 0.0356 - val_accuracy: 0.8598 - val_loss: 0.9301\nEpoch 253/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0346 - val_accuracy: 0.8591 - val_loss: 0.9320\nEpoch 254/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0346 - val_accuracy: 0.8595 - val_loss: 0.9372\nEpoch 255/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0342 - val_accuracy: 0.8595 - val_loss: 0.9413\nEpoch 256/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0348 - val_accuracy: 0.8595 - val_loss: 0.9419\nEpoch 257/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0336 - val_accuracy: 0.8595 - val_loss: 0.9456\nEpoch 258/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0339 - val_accuracy: 0.8596 - val_loss: 0.9417\nEpoch 259/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.0328 - val_accuracy: 0.8588 - val_loss: 0.9448\nEpoch 260/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0327 - val_accuracy: 0.8590 - val_loss: 0.9456\nEpoch 261/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0330 - val_accuracy: 0.8598 - val_loss: 0.9439\nEpoch 262/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0326 - val_accuracy: 0.8584 - val_loss: 0.9453\nEpoch 263/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9893 - loss: 0.0328 - val_accuracy: 0.8593 - val_loss: 0.9430\nEpoch 264/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0321 - val_accuracy: 0.8581 - val_loss: 0.9522\nEpoch 265/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0316 - val_accuracy: 0.8590 - val_loss: 0.9550\nEpoch 266/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.0323 - val_accuracy: 0.8601 - val_loss: 0.9544\nEpoch 267/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0317 - val_accuracy: 0.8588 - val_loss: 0.9548\nEpoch 268/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0313 - val_accuracy: 0.8597 - val_loss: 0.9573\nEpoch 269/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0322 - val_accuracy: 0.8593 - val_loss: 0.9578\nEpoch 270/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0321 - val_accuracy: 0.8591 - val_loss: 0.9553\nEpoch 271/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0315 - val_accuracy: 0.8589 - val_loss: 0.9572\nEpoch 272/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0319 - val_accuracy: 0.8589 - val_loss: 0.9581\nEpoch 273/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0311 - val_accuracy: 0.8582 - val_loss: 0.9636\nEpoch 274/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0311 - val_accuracy: 0.8587 - val_loss: 0.9611\nEpoch 275/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0317 - val_accuracy: 0.8594 - val_loss: 0.9575\nEpoch 276/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0311 - val_accuracy: 0.8590 - val_loss: 0.9624\nEpoch 277/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.8600 - val_loss: 0.9630\nEpoch 278/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0307 - val_accuracy: 0.8592 - val_loss: 0.9692\nEpoch 279/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0297 - val_accuracy: 0.8592 - val_loss: 0.9640\nEpoch 280/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0297 - val_accuracy: 0.8596 - val_loss: 0.9622\nEpoch 281/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0296 - val_accuracy: 0.8596 - val_loss: 0.9669\nEpoch 282/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0302 - val_accuracy: 0.8591 - val_loss: 0.9712\nEpoch 283/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0297 - val_accuracy: 0.8587 - val_loss: 0.9728\nEpoch 284/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0289 - val_accuracy: 0.8587 - val_loss: 0.9712\nEpoch 285/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.0300 - val_accuracy: 0.8587 - val_loss: 0.9721\nEpoch 286/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0290 - val_accuracy: 0.8586 - val_loss: 0.9732\nEpoch 287/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0312 - val_accuracy: 0.8586 - val_loss: 0.9755\nEpoch 288/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0296 - val_accuracy: 0.8589 - val_loss: 0.9702\nEpoch 289/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0295 - val_accuracy: 0.8596 - val_loss: 0.9746\nEpoch 290/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0299 - val_accuracy: 0.8588 - val_loss: 0.9749\nEpoch 291/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0289 - val_accuracy: 0.8593 - val_loss: 0.9788\nEpoch 292/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.0289 - val_accuracy: 0.8587 - val_loss: 0.9784\nEpoch 293/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0289 - val_accuracy: 0.8589 - val_loss: 0.9799\nEpoch 294/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0284 - val_accuracy: 0.8593 - val_loss: 0.9771\nEpoch 295/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0286 - val_accuracy: 0.8590 - val_loss: 0.9817\nEpoch 296/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9904 - loss: 0.0281 - val_accuracy: 0.8594 - val_loss: 0.9823\nEpoch 297/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0290 - val_accuracy: 0.8594 - val_loss: 0.9797\nEpoch 298/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0278 - val_accuracy: 0.8598 - val_loss: 0.9862\nEpoch 299/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0275 - val_accuracy: 0.8588 - val_loss: 0.9923\nEpoch 300/300\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0282 - val_accuracy: 0.8592 - val_loss: 0.9873\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Run sampling","metadata":{}},{"cell_type":"code","source":"# Define sampling models\n# Restore the model and construct the encoder and decoder.\nmodel = keras.models.load_model(\"s2s_model.keras\")\n\nencoder_inputs = model.input[0]  # input_1\nencoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = keras.Model(encoder_inputs, encoder_states)\n\ndecoder_inputs = model.input[1]  # input_2\ndecoder_state_input_h = keras.Input(shape=(latent_dim,))\ndecoder_state_input_c = keras.Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\ndecoder_lstm = model.layers[3]\ndecoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs\n)\ndecoder_states = [state_h_dec, state_c_dec]\ndecoder_dense = model.layers[4]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = keras.Model(\n    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n)\n\n# Reverse-lookup token index to decode sequences back to\n# something readable.\nreverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\nreverse_target_char_index = dict((i, char) for char, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:20:51.524524Z","iopub.execute_input":"2025-02-09T00:20:51.525386Z","iopub.status.idle":"2025-02-09T00:20:51.669356Z","shell.execute_reply.started":"2025-02-09T00:20:51.525344Z","shell.execute_reply":"2025-02-09T00:20:51.668707Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq, verbose=0)\n\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = \"\"\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict(\n            [target_seq] + states_value, verbose=0\n        )\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1, 1, num_decoder_tokens))\n        target_seq[0, 0, sampled_token_index] = 1.0\n\n        # Update states\n        states_value = [h, c]\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:20:55.764021Z","iopub.execute_input":"2025-02-09T00:20:55.764748Z","iopub.status.idle":"2025-02-09T00:20:55.771412Z","shell.execute_reply.started":"2025-02-09T00:20:55.764712Z","shell.execute_reply":"2025-02-09T00:20:55.770275Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"for seq_index in range(20):\n    # Take one sequence (part of the training set)\n    # for trying out decoding.\n    input_seq = encoder_input_data[seq_index : seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print(\"-\")\n    print(\"Input sentence:\", input_texts[seq_index])\n    print(\"Decoded sentence:\", decoded_sentence)","metadata":{"execution":{"iopub.status.busy":"2025-02-09T00:20:57.908904Z","iopub.execute_input":"2025-02-09T00:20:57.909941Z","iopub.status.idle":"2025-02-09T00:21:09.978458Z","shell.execute_reply.started":"2025-02-09T00:20:57.909892Z","shell.execute_reply":"2025-02-09T00:21:09.977472Z"},"trusted":true},"outputs":[{"name":"stdout","text":"-\nInput sentence: Go.\nDecoded sentence: Geh.\n\n-\nInput sentence: Hi.\nDecoded sentence: Hallo!\n\n-\nInput sentence: Hi.\nDecoded sentence: Hallo!\n\n-\nInput sentence: Run!\nDecoded sentence: Lauf!\n\n-\nInput sentence: Run.\nDecoded sentence: Lauf!\n\n-\nInput sentence: Wow!\nDecoded sentence: Donnerwetter!\n\n-\nInput sentence: Wow!\nDecoded sentence: Donnerwetter!\n\n-\nInput sentence: Duck!\nDecoded sentence: Kopf runter!\n\n-\nInput sentence: Fire!\nDecoded sentence: Feuer!\n\n-\nInput sentence: Help!\nDecoded sentence: Zu Hülf!\n\n-\nInput sentence: Help!\nDecoded sentence: Zu Hülf!\n\n-\nInput sentence: Hide.\nDecoded sentence: Versteck dich!\n\n-\nInput sentence: Hide.\nDecoded sentence: Versteck dich!\n\n-\nInput sentence: Stay.\nDecoded sentence: Bleib!\n\n-\nInput sentence: Stop!\nDecoded sentence: Anhalten!\n\n-\nInput sentence: Stop!\nDecoded sentence: Anhalten!\n\n-\nInput sentence: Wait!\nDecoded sentence: Warte!\n\n-\nInput sentence: Wait.\nDecoded sentence: Warte.\n\n-\nInput sentence: Begin.\nDecoded sentence: Fang an.\n\n-\nInput sentence: Do it.\nDecoded sentence: Tue es.\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}